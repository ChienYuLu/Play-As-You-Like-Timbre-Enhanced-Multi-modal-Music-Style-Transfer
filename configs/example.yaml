# Copyright (C) 2017 NVIDIA Corporation.  All rights reserved.
# Licensed under the CC BY-NC-SA 4.0 license (https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode).

# logger options
image_save_iter: 10000        # How often do you want to save output images during training
image_display_iter: 5000      # How often do you want to display output images during training
display_size: 4               # How many images do you want to display each time
snapshot_save_iter: 10000     # How often do you want to save trained models
log_iter: 1                   # How often do you want to log the training stats

# optimization options
max_iter: 600000              # maximum number of training iterations
batch_size: 1                 # batch size
weight_decay: 0.0001          # weight decay
beta1: 0.5                    # Adam parameter
beta2: 0.999                  # Adam parameter
init: kaiming                 # initialization [gaussian/kaiming/xavier/orthogonal]
lr: 0.0001                    # initial learning rate
lr_policy: step               # learning rate scheduler
step_size: 100000             # how often to decay learning rate
gamma: 0.5                    # how much to decay learning rate
gan_w: 1                      # weight of adversarial loss
recon_x_w: 10                 # weight of image reconstruction loss
recon_s_w: 1                  # weight of style reconstruction loss
recon_c_w: 1                  # weight of content reconstruction loss
recon_x_cyc_w: 0              # weight of explicit style augmented cycle consistency loss
ceps_w: 1                     # weight of cepstrum in intrinsic consistency loss
flux_w: 1                     # weight of spectral flux in intrinsic consistency loss
enve_w: 1                     # weight of spectral envelope in intrinsic consistency loss
vol_w: 1                      # weight of volume loss
clip_grad: 'value'            # gradient clipping on encoder and decoder [value/norm/None]

# model options
gen:
  dim: 64                     # number of filters in the bottommost layer
  mlp_dim: 256                # number of filters in MLP
  style_dim: 8                # length of style code
  activ: relu                 # activation function [relu/lrelu/prelu/selu/tanh]
  n_downsample: 2             # number of downsampling layers in content encoder
  n_res: 4                    # number of residual blocks in content encoder/decoder
  pad_type: reflect           # padding type [zero/replicate/reflect]
  dconv: False                # use dconv instead of upsample + conv in decoder [True/False]
dis:
  dim: 64                     # number of filters in the bottommost layer
  norm: none                  # normalization layer [none/bn/in/ln]
  activ: lrelu                # activation function [relu/lrelu/prelu/selu/tanh]
  n_layer: 4                  # number of layers in D
  gan_type: ralsgan           # GAN loss [lsgan/nsgan/ralsgan]
  num_scales: 3               # number of scales
  pad_type: reflect           # padding type [zero/replicate/reflect]

# data options
input_dim_a: 4                # number of input channels [1/4]
input_dim_b: 4                # number of input channels [1/4]
num_workers: 8                # number of data loading threads
new_size: 256                 # first resize the shortest input side to this size
crop_image_height: 256        # random crop input of this height
crop_image_width: 256         # random crop input of this width
fft_size: 2048                # fft size
hop_length: 256               # hop_length
recon_audio_hei: 256          # the crop size may differ from #frequency_bins
exp_b: 0.3
n_mels: 256
use_ceps: True                # True or False, only effect num_channels
use_diff_spec: True           # True or False, only effect num_channels
use_spec_enve: True           # True or False, only effect num_channels

data_root: ./dataset/pia2vio_example/     # dataset folder location